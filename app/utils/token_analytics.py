"""An√°lise de consumo de tokens e custos."""

import logging
from typing import Dict, Any

logger = logging.getLogger(__name__)


# Pre√ßos por 1M tokens (atualizado Nov 2024)
TOKEN_PRICES = {
    "gpt-4o-mini": {
        "input": 0.150,   # $0.150 por 1M tokens de input
        "output": 0.600,  # $0.600 por 1M tokens de output
    },
    "gpt-4o": {
        "input": 2.50,    # $2.50 por 1M tokens de input
        "output": 10.00,  # $10.00 por 1M tokens de output
    },
    "gpt-4-turbo": {
        "input": 10.00,   # $10.00 por 1M tokens de input
        "output": 30.00,  # $30.00 por 1M tokens de output
    }
}


def calculate_cost(
    prompt_tokens: int,
    completion_tokens: int,
    model: str = "gpt-4o-mini"
) -> Dict[str, Any]:
    """
    Calcula custo de uma chamada √† API OpenAI.
    
    Args:
        prompt_tokens: Tokens de entrada (prompt)
        completion_tokens: Tokens de sa√≠da (completion)
        model: Nome do modelo usado
        
    Returns:
        Dict com an√°lise de custos
    """
    if model not in TOKEN_PRICES:
        logger.warning(f"Modelo {model} n√£o encontrado na tabela de pre√ßos")
        return {
            "error": f"Modelo {model} n√£o suportado",
            "prompt_tokens": prompt_tokens,
            "completion_tokens": completion_tokens,
            "total_tokens": prompt_tokens + completion_tokens
        }
    
    prices = TOKEN_PRICES[model]
    
    # Calcular custos (pre√ßo √© por 1M tokens)
    input_cost = (prompt_tokens / 1_000_000) * prices["input"]
    output_cost = (completion_tokens / 1_000_000) * prices["output"]
    total_cost = input_cost + output_cost
    
    # Calcular custo por 1000 intera√ß√µes
    cost_per_1k = total_cost * 1000
    
    # Calcular custo mensal estimado (assumindo 30 intera√ß√µes/dia)
    daily_interactions = 30
    monthly_cost = total_cost * daily_interactions * 30
    
    return {
        "model": model,
        "prompt_tokens": prompt_tokens,
        "completion_tokens": completion_tokens,
        "total_tokens": prompt_tokens + completion_tokens,
        "input_cost_usd": round(input_cost, 6),
        "output_cost_usd": round(output_cost, 6),
        "total_cost_usd": round(total_cost, 6),
        "cost_per_1k_interactions": round(cost_per_1k, 2),
        "estimated_monthly_cost": round(monthly_cost, 2),
        "cost_breakdown": {
            "input_price_per_1m": prices["input"],
            "output_price_per_1m": prices["output"]
        }
    }


def analyze_conversation_cost(
    iterations: int,
    avg_prompt_tokens: int,
    avg_completion_tokens: int,
    model: str = "gpt-4o-mini"
) -> Dict[str, Any]:
    """
    Analisa custo de uma conversa completa com m√∫ltiplas itera√ß√µes.
    
    Args:
        iterations: N√∫mero de itera√ß√µes (chamadas √† API)
        avg_prompt_tokens: M√©dia de tokens de prompt por itera√ß√£o
        avg_completion_tokens: M√©dia de tokens de completion por itera√ß√£o
        model: Nome do modelo usado
        
    Returns:
        Dict com an√°lise de custos da conversa
    """
    total_prompt = avg_prompt_tokens * iterations
    total_completion = avg_completion_tokens * iterations
    
    cost_analysis = calculate_cost(total_prompt, total_completion, model)
    cost_analysis["iterations"] = iterations
    cost_analysis["avg_prompt_per_iteration"] = avg_prompt_tokens
    cost_analysis["avg_completion_per_iteration"] = avg_completion_tokens
    
    return cost_analysis


def is_usage_high(
    prompt_tokens: int,
    completion_tokens: int,
    threshold_prompt: int = 4000,
    threshold_completion: int = 1000
) -> Dict[str, Any]:
    """
    Verifica se o uso de tokens est√° alto.
    
    Args:
        prompt_tokens: Tokens de entrada
        completion_tokens: Tokens de sa√≠da
        threshold_prompt: Limite para prompt (padr√£o: 4000)
        threshold_completion: Limite para completion (padr√£o: 1000)
        
    Returns:
        Dict com an√°lise de uso
    """
    total = prompt_tokens + completion_tokens
    
    return {
        "is_high": prompt_tokens > threshold_prompt or completion_tokens > threshold_completion,
        "prompt_status": "üî¥ ALTO" if prompt_tokens > threshold_prompt else "üü¢ OK",
        "completion_status": "üî¥ ALTO" if completion_tokens > threshold_completion else "üü¢ OK",
        "total_tokens": total,
        "recommendations": _get_recommendations(prompt_tokens, completion_tokens, threshold_prompt, threshold_completion)
    }


def _get_recommendations(
    prompt_tokens: int,
    completion_tokens: int,
    threshold_prompt: int,
    threshold_completion: int
) -> list:
    """Gera recomenda√ß√µes para reduzir uso de tokens."""
    recommendations = []
    
    if prompt_tokens > threshold_prompt:
        recommendations.append("‚ö†Ô∏è Prompt muito grande - considere:")
        recommendations.append("  ‚Ä¢ Reduzir instru√ß√µes redundantes")
        recommendations.append("  ‚Ä¢ Limitar hist√≥rico de conversa")
        recommendations.append("  ‚Ä¢ Usar exemplos mais concisos")
    
    if completion_tokens > threshold_completion:
        recommendations.append("‚ö†Ô∏è Resposta muito longa - considere:")
        recommendations.append("  ‚Ä¢ Instruir IA a ser mais concisa")
        recommendations.append("  ‚Ä¢ Limitar n√∫mero de lojas exibidas")
        recommendations.append("  ‚Ä¢ Reduzir detalhes nas respostas")
    
    if not recommendations:
        recommendations.append("‚úÖ Uso de tokens est√° dentro do esperado")
    
    return recommendations


__all__ = [
    "calculate_cost",
    "analyze_conversation_cost",
    "is_usage_high",
    "TOKEN_PRICES"
]
